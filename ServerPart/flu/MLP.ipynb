{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense,BatchNormalization\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"train_dataset.csv\")\n",
    "test_dataset = pd.read_csv(\"test_dataset.csv\")\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "train_labels = train_features.pop('seasonal_vaccine')\n",
    "test_labels = test_features.pop('seasonal_vaccine')\n",
    "X = train_features.to_numpy()\n",
    "Y = train_labels.to_numpy()\n",
    "test_X = test_features.to_numpy()\n",
    "test_Y = test_labels.to_numpy()\n",
    "input_shape = (32,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8256"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 5,658\n",
      "Trainable params: 5,594\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_dim=X.shape[1]))\n",
    "#model.add(Dense(16,input_dim=X.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dense(8,activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "372/372 - 0s - loss: 0.7109 - accuracy: 0.4949 - val_loss: 0.6987 - val_accuracy: 0.5121\n",
      "Epoch 2/2000\n",
      "372/372 - 0s - loss: 0.6982 - accuracy: 0.5129 - val_loss: 0.6907 - val_accuracy: 0.5351\n",
      "Epoch 3/2000\n",
      "372/372 - 0s - loss: 0.6903 - accuracy: 0.5355 - val_loss: 0.6849 - val_accuracy: 0.5533\n",
      "Epoch 4/2000\n",
      "372/372 - 0s - loss: 0.6852 - accuracy: 0.5592 - val_loss: 0.6800 - val_accuracy: 0.5908\n",
      "Epoch 5/2000\n",
      "372/372 - 0s - loss: 0.6805 - accuracy: 0.5795 - val_loss: 0.6753 - val_accuracy: 0.6126\n",
      "Epoch 6/2000\n",
      "372/372 - 0s - loss: 0.6759 - accuracy: 0.6046 - val_loss: 0.6707 - val_accuracy: 0.6392\n",
      "Epoch 7/2000\n",
      "372/372 - 0s - loss: 0.6712 - accuracy: 0.6209 - val_loss: 0.6654 - val_accuracy: 0.6416\n",
      "Epoch 8/2000\n",
      "372/372 - 0s - loss: 0.6647 - accuracy: 0.6384 - val_loss: 0.6602 - val_accuracy: 0.6634\n",
      "Epoch 9/2000\n",
      "372/372 - 0s - loss: 0.6608 - accuracy: 0.6530 - val_loss: 0.6545 - val_accuracy: 0.6695\n",
      "Epoch 10/2000\n",
      "372/372 - 0s - loss: 0.6551 - accuracy: 0.6549 - val_loss: 0.6478 - val_accuracy: 0.6804\n",
      "Epoch 11/2000\n",
      "372/372 - 0s - loss: 0.6483 - accuracy: 0.6670 - val_loss: 0.6407 - val_accuracy: 0.6840\n",
      "Epoch 12/2000\n",
      "372/372 - 0s - loss: 0.6405 - accuracy: 0.6760 - val_loss: 0.6332 - val_accuracy: 0.6852\n",
      "Epoch 13/2000\n",
      "372/372 - 0s - loss: 0.6337 - accuracy: 0.6836 - val_loss: 0.6253 - val_accuracy: 0.7010\n",
      "Epoch 14/2000\n",
      "372/372 - 0s - loss: 0.6263 - accuracy: 0.6931 - val_loss: 0.6179 - val_accuracy: 0.7107\n",
      "Epoch 15/2000\n",
      "372/372 - 0s - loss: 0.6185 - accuracy: 0.6983 - val_loss: 0.6094 - val_accuracy: 0.7167\n",
      "Epoch 16/2000\n",
      "372/372 - 0s - loss: 0.6106 - accuracy: 0.7066 - val_loss: 0.6014 - val_accuracy: 0.7131\n",
      "Epoch 17/2000\n",
      "372/372 - 0s - loss: 0.6044 - accuracy: 0.7104 - val_loss: 0.5930 - val_accuracy: 0.7167\n",
      "Epoch 18/2000\n",
      "372/372 - 0s - loss: 0.5963 - accuracy: 0.7153 - val_loss: 0.5865 - val_accuracy: 0.7215\n",
      "Epoch 19/2000\n",
      "372/372 - 0s - loss: 0.5891 - accuracy: 0.7197 - val_loss: 0.5792 - val_accuracy: 0.7215\n",
      "Epoch 20/2000\n",
      "372/372 - 0s - loss: 0.5800 - accuracy: 0.7242 - val_loss: 0.5729 - val_accuracy: 0.7264\n",
      "Epoch 21/2000\n",
      "372/372 - 0s - loss: 0.5750 - accuracy: 0.7300 - val_loss: 0.5659 - val_accuracy: 0.7349\n",
      "Epoch 22/2000\n",
      "372/372 - 0s - loss: 0.5696 - accuracy: 0.7376 - val_loss: 0.5603 - val_accuracy: 0.7421\n",
      "Epoch 23/2000\n",
      "372/372 - 0s - loss: 0.5610 - accuracy: 0.7421 - val_loss: 0.5547 - val_accuracy: 0.7446\n",
      "Epoch 24/2000\n",
      "372/372 - 0s - loss: 0.5590 - accuracy: 0.7384 - val_loss: 0.5499 - val_accuracy: 0.7470\n",
      "Epoch 25/2000\n",
      "372/372 - 0s - loss: 0.5536 - accuracy: 0.7401 - val_loss: 0.5458 - val_accuracy: 0.7542\n",
      "Epoch 26/2000\n",
      "372/372 - 0s - loss: 0.5505 - accuracy: 0.7476 - val_loss: 0.5417 - val_accuracy: 0.7518\n",
      "Epoch 27/2000\n",
      "372/372 - 0s - loss: 0.5438 - accuracy: 0.7485 - val_loss: 0.5377 - val_accuracy: 0.7542\n",
      "Epoch 28/2000\n",
      "372/372 - 0s - loss: 0.5418 - accuracy: 0.7532 - val_loss: 0.5342 - val_accuracy: 0.7579\n",
      "Epoch 29/2000\n",
      "372/372 - 0s - loss: 0.5377 - accuracy: 0.7528 - val_loss: 0.5312 - val_accuracy: 0.7639\n",
      "Epoch 30/2000\n",
      "372/372 - 0s - loss: 0.5347 - accuracy: 0.7569 - val_loss: 0.5284 - val_accuracy: 0.7663\n",
      "Epoch 31/2000\n",
      "372/372 - 0s - loss: 0.5349 - accuracy: 0.7549 - val_loss: 0.5259 - val_accuracy: 0.7688\n",
      "Epoch 32/2000\n",
      "372/372 - 0s - loss: 0.5300 - accuracy: 0.7546 - val_loss: 0.5232 - val_accuracy: 0.7663\n",
      "Epoch 33/2000\n",
      "372/372 - 0s - loss: 0.5289 - accuracy: 0.7541 - val_loss: 0.5210 - val_accuracy: 0.7663\n",
      "Epoch 34/2000\n",
      "372/372 - 0s - loss: 0.5242 - accuracy: 0.7587 - val_loss: 0.5192 - val_accuracy: 0.7663\n",
      "Epoch 35/2000\n",
      "372/372 - 0s - loss: 0.5213 - accuracy: 0.7611 - val_loss: 0.5175 - val_accuracy: 0.7663\n",
      "Epoch 36/2000\n",
      "372/372 - 0s - loss: 0.5196 - accuracy: 0.7630 - val_loss: 0.5149 - val_accuracy: 0.7688\n",
      "Epoch 37/2000\n",
      "372/372 - 0s - loss: 0.5172 - accuracy: 0.7616 - val_loss: 0.5134 - val_accuracy: 0.7700\n",
      "Epoch 38/2000\n",
      "372/372 - 0s - loss: 0.5132 - accuracy: 0.7661 - val_loss: 0.5119 - val_accuracy: 0.7700\n",
      "Epoch 39/2000\n",
      "372/372 - 0s - loss: 0.5114 - accuracy: 0.7678 - val_loss: 0.5100 - val_accuracy: 0.7700\n",
      "Epoch 40/2000\n",
      "372/372 - 0s - loss: 0.5117 - accuracy: 0.7647 - val_loss: 0.5084 - val_accuracy: 0.7688\n",
      "Epoch 41/2000\n",
      "372/372 - 0s - loss: 0.5087 - accuracy: 0.7732 - val_loss: 0.5074 - val_accuracy: 0.7712\n",
      "Epoch 42/2000\n",
      "372/372 - 0s - loss: 0.5074 - accuracy: 0.7662 - val_loss: 0.5061 - val_accuracy: 0.7688\n",
      "Epoch 43/2000\n",
      "372/372 - 0s - loss: 0.5055 - accuracy: 0.7717 - val_loss: 0.5049 - val_accuracy: 0.7688\n",
      "Epoch 44/2000\n",
      "372/372 - 0s - loss: 0.5066 - accuracy: 0.7647 - val_loss: 0.5035 - val_accuracy: 0.7700\n",
      "Epoch 45/2000\n",
      "372/372 - 0s - loss: 0.5025 - accuracy: 0.7725 - val_loss: 0.5026 - val_accuracy: 0.7688\n",
      "Epoch 46/2000\n",
      "372/372 - 0s - loss: 0.5041 - accuracy: 0.7723 - val_loss: 0.5010 - val_accuracy: 0.7663\n",
      "Epoch 47/2000\n",
      "372/372 - 0s - loss: 0.5023 - accuracy: 0.7694 - val_loss: 0.4999 - val_accuracy: 0.7700\n",
      "Epoch 48/2000\n",
      "372/372 - 0s - loss: 0.4998 - accuracy: 0.7721 - val_loss: 0.4990 - val_accuracy: 0.7712\n",
      "Epoch 49/2000\n",
      "372/372 - 0s - loss: 0.5003 - accuracy: 0.7717 - val_loss: 0.4980 - val_accuracy: 0.7712\n",
      "Epoch 50/2000\n",
      "372/372 - 0s - loss: 0.4974 - accuracy: 0.7719 - val_loss: 0.4969 - val_accuracy: 0.7724\n",
      "Epoch 51/2000\n",
      "372/372 - 0s - loss: 0.4964 - accuracy: 0.7763 - val_loss: 0.4964 - val_accuracy: 0.7748\n",
      "Epoch 52/2000\n",
      "372/372 - 0s - loss: 0.4981 - accuracy: 0.7727 - val_loss: 0.4954 - val_accuracy: 0.7760\n",
      "Epoch 53/2000\n",
      "372/372 - 0s - loss: 0.4982 - accuracy: 0.7689 - val_loss: 0.4950 - val_accuracy: 0.7748\n",
      "Epoch 54/2000\n",
      "372/372 - 0s - loss: 0.4957 - accuracy: 0.7739 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
      "Epoch 55/2000\n",
      "372/372 - 0s - loss: 0.4944 - accuracy: 0.7756 - val_loss: 0.4933 - val_accuracy: 0.7748\n",
      "Epoch 56/2000\n",
      "372/372 - 0s - loss: 0.4911 - accuracy: 0.7756 - val_loss: 0.4926 - val_accuracy: 0.7785\n",
      "Epoch 57/2000\n",
      "372/372 - 0s - loss: 0.4909 - accuracy: 0.7773 - val_loss: 0.4914 - val_accuracy: 0.7772\n",
      "Epoch 58/2000\n",
      "372/372 - 0s - loss: 0.4953 - accuracy: 0.7705 - val_loss: 0.4902 - val_accuracy: 0.7785\n",
      "Epoch 59/2000\n",
      "372/372 - 0s - loss: 0.4926 - accuracy: 0.7779 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
      "Epoch 60/2000\n",
      "372/372 - 0s - loss: 0.4890 - accuracy: 0.7799 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
      "Epoch 61/2000\n",
      "372/372 - 0s - loss: 0.4922 - accuracy: 0.7789 - val_loss: 0.4889 - val_accuracy: 0.7772\n",
      "Epoch 62/2000\n",
      "372/372 - 0s - loss: 0.4868 - accuracy: 0.7769 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
      "Epoch 63/2000\n",
      "372/372 - 0s - loss: 0.4872 - accuracy: 0.7805 - val_loss: 0.4873 - val_accuracy: 0.7712\n",
      "Epoch 64/2000\n",
      "372/372 - 0s - loss: 0.4870 - accuracy: 0.7763 - val_loss: 0.4869 - val_accuracy: 0.7772\n",
      "Epoch 65/2000\n",
      "372/372 - 0s - loss: 0.4873 - accuracy: 0.7809 - val_loss: 0.4866 - val_accuracy: 0.7748\n",
      "Epoch 66/2000\n",
      "372/372 - 0s - loss: 0.4867 - accuracy: 0.7763 - val_loss: 0.4867 - val_accuracy: 0.7748\n",
      "Epoch 67/2000\n",
      "372/372 - 0s - loss: 0.4911 - accuracy: 0.7740 - val_loss: 0.4862 - val_accuracy: 0.7797\n",
      "Epoch 68/2000\n",
      "372/372 - 0s - loss: 0.4860 - accuracy: 0.7814 - val_loss: 0.4851 - val_accuracy: 0.7712\n",
      "Epoch 69/2000\n",
      "372/372 - 0s - loss: 0.4817 - accuracy: 0.7844 - val_loss: 0.4842 - val_accuracy: 0.7724\n",
      "Epoch 70/2000\n",
      "372/372 - 0s - loss: 0.4846 - accuracy: 0.7798 - val_loss: 0.4840 - val_accuracy: 0.7748\n",
      "Epoch 71/2000\n",
      "372/372 - 0s - loss: 0.4842 - accuracy: 0.7782 - val_loss: 0.4832 - val_accuracy: 0.7772\n",
      "Epoch 72/2000\n",
      "372/372 - 0s - loss: 0.4841 - accuracy: 0.7821 - val_loss: 0.4836 - val_accuracy: 0.7748\n",
      "Epoch 73/2000\n",
      "372/372 - 0s - loss: 0.4801 - accuracy: 0.7763 - val_loss: 0.4826 - val_accuracy: 0.7736\n",
      "Epoch 74/2000\n",
      "372/372 - 0s - loss: 0.4813 - accuracy: 0.7786 - val_loss: 0.4826 - val_accuracy: 0.7772\n",
      "Epoch 75/2000\n",
      "372/372 - 0s - loss: 0.4827 - accuracy: 0.7805 - val_loss: 0.4828 - val_accuracy: 0.7772\n",
      "Epoch 76/2000\n",
      "372/372 - 0s - loss: 0.4795 - accuracy: 0.7791 - val_loss: 0.4826 - val_accuracy: 0.7772\n",
      "Epoch 77/2000\n",
      "372/372 - 0s - loss: 0.4837 - accuracy: 0.7779 - val_loss: 0.4824 - val_accuracy: 0.7748\n",
      "Epoch 78/2000\n",
      "372/372 - 0s - loss: 0.4824 - accuracy: 0.7785 - val_loss: 0.4815 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/2000\n",
      "372/372 - 0s - loss: 0.4846 - accuracy: 0.7820 - val_loss: 0.4812 - val_accuracy: 0.7760\n",
      "Epoch 80/2000\n",
      "372/372 - 0s - loss: 0.4811 - accuracy: 0.7799 - val_loss: 0.4809 - val_accuracy: 0.7785\n",
      "Epoch 81/2000\n",
      "372/372 - 0s - loss: 0.4808 - accuracy: 0.7771 - val_loss: 0.4802 - val_accuracy: 0.7772\n",
      "Epoch 82/2000\n",
      "372/372 - 0s - loss: 0.4801 - accuracy: 0.7787 - val_loss: 0.4799 - val_accuracy: 0.7736\n",
      "Epoch 83/2000\n",
      "372/372 - 0s - loss: 0.4794 - accuracy: 0.7798 - val_loss: 0.4798 - val_accuracy: 0.7748\n",
      "Epoch 84/2000\n",
      "372/372 - 0s - loss: 0.4783 - accuracy: 0.7786 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 85/2000\n",
      "372/372 - 0s - loss: 0.4775 - accuracy: 0.7857 - val_loss: 0.4789 - val_accuracy: 0.7760\n",
      "Epoch 86/2000\n",
      "372/372 - 0s - loss: 0.4786 - accuracy: 0.7793 - val_loss: 0.4792 - val_accuracy: 0.7785\n",
      "Epoch 87/2000\n",
      "372/372 - 0s - loss: 0.4797 - accuracy: 0.7852 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 88/2000\n",
      "372/372 - 0s - loss: 0.4840 - accuracy: 0.7750 - val_loss: 0.4783 - val_accuracy: 0.7785\n",
      "Epoch 89/2000\n",
      "372/372 - 0s - loss: 0.4773 - accuracy: 0.7837 - val_loss: 0.4774 - val_accuracy: 0.7772\n",
      "Epoch 90/2000\n",
      "372/372 - 0s - loss: 0.4735 - accuracy: 0.7849 - val_loss: 0.4779 - val_accuracy: 0.7772\n",
      "Epoch 91/2000\n",
      "372/372 - 0s - loss: 0.4739 - accuracy: 0.7844 - val_loss: 0.4776 - val_accuracy: 0.7772\n",
      "Epoch 92/2000\n",
      "372/372 - 0s - loss: 0.4732 - accuracy: 0.7855 - val_loss: 0.4773 - val_accuracy: 0.7797\n",
      "Epoch 93/2000\n",
      "372/372 - 0s - loss: 0.4744 - accuracy: 0.7844 - val_loss: 0.4767 - val_accuracy: 0.7785\n",
      "Epoch 94/2000\n",
      "372/372 - 0s - loss: 0.4722 - accuracy: 0.7875 - val_loss: 0.4767 - val_accuracy: 0.7797\n",
      "Epoch 95/2000\n",
      "372/372 - 0s - loss: 0.4729 - accuracy: 0.7891 - val_loss: 0.4769 - val_accuracy: 0.7785\n",
      "Epoch 96/2000\n",
      "372/372 - 0s - loss: 0.4735 - accuracy: 0.7860 - val_loss: 0.4765 - val_accuracy: 0.7760\n",
      "Epoch 97/2000\n",
      "372/372 - 0s - loss: 0.4767 - accuracy: 0.7806 - val_loss: 0.4761 - val_accuracy: 0.7797\n",
      "Epoch 98/2000\n",
      "372/372 - 0s - loss: 0.4704 - accuracy: 0.7828 - val_loss: 0.4760 - val_accuracy: 0.7797\n",
      "Epoch 99/2000\n",
      "372/372 - 0s - loss: 0.4788 - accuracy: 0.7812 - val_loss: 0.4754 - val_accuracy: 0.7809\n",
      "Epoch 100/2000\n",
      "372/372 - 0s - loss: 0.4732 - accuracy: 0.7836 - val_loss: 0.4760 - val_accuracy: 0.7833\n",
      "Epoch 101/2000\n",
      "372/372 - 0s - loss: 0.4719 - accuracy: 0.7828 - val_loss: 0.4752 - val_accuracy: 0.7821\n",
      "Epoch 102/2000\n",
      "372/372 - 0s - loss: 0.4738 - accuracy: 0.7791 - val_loss: 0.4755 - val_accuracy: 0.7833\n",
      "Epoch 103/2000\n",
      "372/372 - 0s - loss: 0.4687 - accuracy: 0.7871 - val_loss: 0.4754 - val_accuracy: 0.7821\n",
      "Epoch 104/2000\n",
      "372/372 - 0s - loss: 0.4696 - accuracy: 0.7882 - val_loss: 0.4748 - val_accuracy: 0.7821\n",
      "Epoch 105/2000\n",
      "372/372 - 0s - loss: 0.4699 - accuracy: 0.7873 - val_loss: 0.4747 - val_accuracy: 0.7797\n",
      "Epoch 106/2000\n",
      "372/372 - 0s - loss: 0.4706 - accuracy: 0.7824 - val_loss: 0.4749 - val_accuracy: 0.7785\n",
      "Epoch 107/2000\n",
      "372/372 - 0s - loss: 0.4688 - accuracy: 0.7902 - val_loss: 0.4739 - val_accuracy: 0.7797\n",
      "Epoch 108/2000\n",
      "372/372 - 0s - loss: 0.4769 - accuracy: 0.7787 - val_loss: 0.4741 - val_accuracy: 0.7809\n",
      "Epoch 109/2000\n",
      "372/372 - 0s - loss: 0.4712 - accuracy: 0.7853 - val_loss: 0.4737 - val_accuracy: 0.7809\n",
      "Epoch 110/2000\n",
      "372/372 - 0s - loss: 0.4668 - accuracy: 0.7841 - val_loss: 0.4739 - val_accuracy: 0.7772\n",
      "Epoch 111/2000\n",
      "372/372 - 0s - loss: 0.4715 - accuracy: 0.7810 - val_loss: 0.4735 - val_accuracy: 0.7797\n",
      "Epoch 112/2000\n",
      "372/372 - 0s - loss: 0.4724 - accuracy: 0.7853 - val_loss: 0.4731 - val_accuracy: 0.7797\n",
      "Epoch 113/2000\n",
      "372/372 - 0s - loss: 0.4701 - accuracy: 0.7883 - val_loss: 0.4732 - val_accuracy: 0.7797\n",
      "Epoch 114/2000\n",
      "372/372 - 0s - loss: 0.4714 - accuracy: 0.7828 - val_loss: 0.4735 - val_accuracy: 0.7785\n",
      "Epoch 115/2000\n",
      "372/372 - 0s - loss: 0.4687 - accuracy: 0.7844 - val_loss: 0.4725 - val_accuracy: 0.7785\n",
      "Epoch 116/2000\n",
      "372/372 - 0s - loss: 0.4734 - accuracy: 0.7840 - val_loss: 0.4731 - val_accuracy: 0.7772\n",
      "Epoch 117/2000\n",
      "372/372 - 0s - loss: 0.4666 - accuracy: 0.7867 - val_loss: 0.4724 - val_accuracy: 0.7785\n",
      "Epoch 118/2000\n",
      "372/372 - 0s - loss: 0.4691 - accuracy: 0.7838 - val_loss: 0.4726 - val_accuracy: 0.7809\n",
      "Epoch 119/2000\n",
      "372/372 - 0s - loss: 0.4696 - accuracy: 0.7822 - val_loss: 0.4729 - val_accuracy: 0.7785\n",
      "Epoch 120/2000\n",
      "372/372 - 0s - loss: 0.4692 - accuracy: 0.7851 - val_loss: 0.4722 - val_accuracy: 0.7797\n",
      "Epoch 121/2000\n",
      "372/372 - 0s - loss: 0.4676 - accuracy: 0.7837 - val_loss: 0.4718 - val_accuracy: 0.7785\n",
      "Epoch 122/2000\n",
      "372/372 - 0s - loss: 0.4668 - accuracy: 0.7882 - val_loss: 0.4714 - val_accuracy: 0.7797\n",
      "Epoch 123/2000\n",
      "372/372 - 0s - loss: 0.4717 - accuracy: 0.7818 - val_loss: 0.4719 - val_accuracy: 0.7809\n",
      "Epoch 124/2000\n",
      "372/372 - 0s - loss: 0.4685 - accuracy: 0.7861 - val_loss: 0.4716 - val_accuracy: 0.7785\n",
      "Epoch 125/2000\n",
      "372/372 - 0s - loss: 0.4680 - accuracy: 0.7888 - val_loss: 0.4717 - val_accuracy: 0.7797\n",
      "Epoch 126/2000\n",
      "372/372 - 0s - loss: 0.4714 - accuracy: 0.7840 - val_loss: 0.4714 - val_accuracy: 0.7785\n",
      "Epoch 127/2000\n",
      "372/372 - 0s - loss: 0.4700 - accuracy: 0.7860 - val_loss: 0.4714 - val_accuracy: 0.7785\n",
      "Epoch 128/2000\n",
      "372/372 - 0s - loss: 0.4685 - accuracy: 0.7879 - val_loss: 0.4717 - val_accuracy: 0.7797\n",
      "Epoch 129/2000\n",
      "372/372 - 0s - loss: 0.4680 - accuracy: 0.7872 - val_loss: 0.4708 - val_accuracy: 0.7797\n",
      "Epoch 130/2000\n",
      "372/372 - 0s - loss: 0.4620 - accuracy: 0.7904 - val_loss: 0.4710 - val_accuracy: 0.7797\n",
      "Epoch 131/2000\n",
      "372/372 - 0s - loss: 0.4634 - accuracy: 0.7900 - val_loss: 0.4712 - val_accuracy: 0.7797\n",
      "Epoch 132/2000\n",
      "372/372 - 0s - loss: 0.4664 - accuracy: 0.7895 - val_loss: 0.4707 - val_accuracy: 0.7797\n",
      "Epoch 133/2000\n",
      "372/372 - 0s - loss: 0.4655 - accuracy: 0.7886 - val_loss: 0.4707 - val_accuracy: 0.7797\n",
      "Epoch 134/2000\n",
      "372/372 - 0s - loss: 0.4681 - accuracy: 0.7848 - val_loss: 0.4708 - val_accuracy: 0.7797\n",
      "Epoch 135/2000\n",
      "372/372 - 0s - loss: 0.4661 - accuracy: 0.7892 - val_loss: 0.4704 - val_accuracy: 0.7797\n",
      "Epoch 136/2000\n",
      "372/372 - 0s - loss: 0.4662 - accuracy: 0.7876 - val_loss: 0.4706 - val_accuracy: 0.7809\n",
      "Epoch 137/2000\n",
      "372/372 - 0s - loss: 0.4625 - accuracy: 0.7907 - val_loss: 0.4699 - val_accuracy: 0.7785\n",
      "Epoch 138/2000\n",
      "372/372 - 0s - loss: 0.4653 - accuracy: 0.7886 - val_loss: 0.4707 - val_accuracy: 0.7797\n",
      "Epoch 139/2000\n",
      "372/372 - 0s - loss: 0.4687 - accuracy: 0.7868 - val_loss: 0.4697 - val_accuracy: 0.7797\n",
      "Epoch 140/2000\n",
      "372/372 - 0s - loss: 0.4639 - accuracy: 0.7857 - val_loss: 0.4701 - val_accuracy: 0.7785\n",
      "Epoch 141/2000\n",
      "372/372 - 0s - loss: 0.4684 - accuracy: 0.7845 - val_loss: 0.4697 - val_accuracy: 0.7797\n",
      "Epoch 142/2000\n",
      "372/372 - 0s - loss: 0.4674 - accuracy: 0.7886 - val_loss: 0.4697 - val_accuracy: 0.7785\n",
      "Epoch 143/2000\n",
      "372/372 - 0s - loss: 0.4639 - accuracy: 0.7904 - val_loss: 0.4696 - val_accuracy: 0.7772\n",
      "Epoch 144/2000\n",
      "372/372 - 0s - loss: 0.4637 - accuracy: 0.7891 - val_loss: 0.4700 - val_accuracy: 0.7772\n",
      "Epoch 145/2000\n",
      "372/372 - 0s - loss: 0.4631 - accuracy: 0.7853 - val_loss: 0.4695 - val_accuracy: 0.7785\n",
      "Epoch 146/2000\n",
      "372/372 - 0s - loss: 0.4633 - accuracy: 0.7906 - val_loss: 0.4693 - val_accuracy: 0.7821\n",
      "Epoch 147/2000\n",
      "372/372 - 0s - loss: 0.4669 - accuracy: 0.7876 - val_loss: 0.4699 - val_accuracy: 0.7760\n",
      "Epoch 148/2000\n",
      "372/372 - 0s - loss: 0.4663 - accuracy: 0.7867 - val_loss: 0.4692 - val_accuracy: 0.7797\n",
      "Epoch 149/2000\n",
      "372/372 - 0s - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.4691 - val_accuracy: 0.7797\n",
      "Epoch 150/2000\n",
      "372/372 - 0s - loss: 0.4680 - accuracy: 0.7868 - val_loss: 0.4692 - val_accuracy: 0.7821\n",
      "Epoch 151/2000\n",
      "372/372 - 0s - loss: 0.4653 - accuracy: 0.7867 - val_loss: 0.4688 - val_accuracy: 0.7797\n",
      "Epoch 152/2000\n",
      "372/372 - 0s - loss: 0.4639 - accuracy: 0.7883 - val_loss: 0.4692 - val_accuracy: 0.7797\n",
      "Epoch 153/2000\n",
      "372/372 - 0s - loss: 0.4652 - accuracy: 0.7891 - val_loss: 0.4689 - val_accuracy: 0.7772\n",
      "Epoch 154/2000\n",
      "372/372 - 0s - loss: 0.4632 - accuracy: 0.7907 - val_loss: 0.4685 - val_accuracy: 0.7785\n",
      "Epoch 155/2000\n",
      "372/372 - 0s - loss: 0.4636 - accuracy: 0.7899 - val_loss: 0.4687 - val_accuracy: 0.7785\n",
      "Epoch 156/2000\n",
      "372/372 - 0s - loss: 0.4606 - accuracy: 0.7913 - val_loss: 0.4688 - val_accuracy: 0.7809\n",
      "Epoch 157/2000\n",
      "372/372 - 0s - loss: 0.4655 - accuracy: 0.7872 - val_loss: 0.4683 - val_accuracy: 0.7821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/2000\n",
      "372/372 - 0s - loss: 0.4615 - accuracy: 0.7898 - val_loss: 0.4682 - val_accuracy: 0.7845\n",
      "Epoch 159/2000\n",
      "372/372 - 0s - loss: 0.4620 - accuracy: 0.7900 - val_loss: 0.4687 - val_accuracy: 0.7821\n",
      "Epoch 160/2000\n",
      "372/372 - 0s - loss: 0.4620 - accuracy: 0.7906 - val_loss: 0.4681 - val_accuracy: 0.7797\n",
      "Epoch 161/2000\n",
      "372/372 - 0s - loss: 0.4647 - accuracy: 0.7856 - val_loss: 0.4683 - val_accuracy: 0.7821\n",
      "Epoch 162/2000\n",
      "372/372 - 0s - loss: 0.4600 - accuracy: 0.7880 - val_loss: 0.4685 - val_accuracy: 0.7821\n",
      "Epoch 163/2000\n",
      "372/372 - 0s - loss: 0.4651 - accuracy: 0.7848 - val_loss: 0.4683 - val_accuracy: 0.7809\n",
      "Epoch 164/2000\n",
      "372/372 - 0s - loss: 0.4589 - accuracy: 0.7911 - val_loss: 0.4685 - val_accuracy: 0.7833\n",
      "Epoch 165/2000\n",
      "372/372 - 0s - loss: 0.4632 - accuracy: 0.7914 - val_loss: 0.4682 - val_accuracy: 0.7809\n",
      "Epoch 166/2000\n",
      "372/372 - 0s - loss: 0.4650 - accuracy: 0.7859 - val_loss: 0.4681 - val_accuracy: 0.7809\n",
      "Epoch 167/2000\n",
      "372/372 - 0s - loss: 0.4648 - accuracy: 0.7896 - val_loss: 0.4685 - val_accuracy: 0.7821\n",
      "Epoch 168/2000\n",
      "372/372 - 0s - loss: 0.4621 - accuracy: 0.7891 - val_loss: 0.4687 - val_accuracy: 0.7809\n",
      "Epoch 169/2000\n",
      "372/372 - 0s - loss: 0.4582 - accuracy: 0.7935 - val_loss: 0.4682 - val_accuracy: 0.7785\n",
      "Epoch 170/2000\n",
      "372/372 - 0s - loss: 0.4624 - accuracy: 0.7891 - val_loss: 0.4685 - val_accuracy: 0.7809\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 5,658\n",
      "Trainable params: 5,594\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.SGD(learning_rate=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=2000, batch_size=20, verbose=2, validation_split=0.1,callbacks=[early_stopping])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-8ac1f9b1b47a>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.796875"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict_classes(X)\n",
    "accuracy_score(Y,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7964064586621342"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\2020F\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\2020F\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: mlp\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
